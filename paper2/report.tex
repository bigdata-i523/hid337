\documentclass[sigconf]{acmart}

\input{format/i523}

\begin{document}
\title{Natural Language Processing (NLP) to analyze human speech data}

\author{Ashok Reddy Singam}
\orcid{HID337}
\affiliation{%
  \institution{Indiana University}
  \streetaddress{711 N Park Ave}
  \city{Bloomington} 
  \state{Indiana} 
  \postcode{47408}
}
\email{asingam@iu.edu}

\author{Anil Ravi}
\orcid{HID333}
\affiliation{%
  \institution{Indiana University}
  \streetaddress{711 N Park Ave}
  \city{Bloomington} 
  \state{Indiana} 
  \postcode{47408}
}
\email{anilravi@iu.edu}

\begin{abstract}
Extracting meaningful information from large volumes of unstructured human language is a challenging big data problem. Automatic speech recognition (ASR) and natural language processing (NLP) based intelligent system can be  used in several human machine interface applications both in consumer and industrial sector. Here describing the architecture, building blocks, performance and applications for such system that would use pre-developed ASR and NLP APIs.
\end{abstract}

\keywords{i523, HID333, HID337, Natural Language Processing, Automatic Speech Recognition, Voic Recognition}


\maketitle


\section{Introduction}
The advancements of digital signal processing, large data processing and natural language processing technologies made speech/voice recognition applications more sophisticated to help solving social and industrial problems. For example, having an intelligent automatic voice recognition system in home to recognize and differentiate between the family members and outsiders would add great value to modern society in terms of assisting in their busy life as well provide necessary help/guidance in offering day-to-day problem solutions, personalized entertainment,  and safety/security. In another example, these systems can provide personalized customer care experience through voice and face recognition by engaging them based on their interests/hobbies. Google home, Alexa, and Siri have become part of the main stream human life activities to seek information and get entertainment by directly speaking with these devices.

The hypothetical intelligent voice system would need the following technologies to work together:
 \begin{itemize}
     \item Highly efficient voice sensors and high speed digital signal processors
     \item Automatic Voice Recognition (AVR) hardware and software algorithms
     \item Machine Learning (ML) algorithms to classify and learn the voice patterns
     \item Machine learning algorithms to understand family members habits and behaviors
     \item Natural Language Processing (NLP) algorithms to precisely recognize and process the voice data
 \end{itemize}
 
 Open Source and/or Other tools:
 \begin{itemize}
     \item Google Cloud Speech API or Alexa Voice Service (AVS)
     \item Audio processing hardware and software algorithms
     \item Natural language processing (NLP) to analyze the speech of family members, friends and strangers
     \item Interfacing with email servers, phone, text message servers
 \end{itemize}
 
 The following sections are organized to review some of the technologies available in the industry and universities and discuss the potential application concepts for home and industry.
 
   The sections are broadly divided in to speech recognition and speaker recognition. In the speech
recognition the focus is on detecting the words irrespective of the personal differences whereas speaker recognition is focused on detecting the physical speaker by discarding the words and their meanings.

   Speech recognition represents speech content and disregards speaker identity whereas speaker 
recognition represents speaker identity but disregards speech content.

\section{SPEAKER RECOGNITION THEORY}
The speaker recognition technology is multidisciplinary, which requires hardware based sensors to convert voice in to electrical signals, speech processing module that converters the electrical signals in to digitized data using advanced digital signal processors (DSP). The basic recognition process involves modeling the acoustic data and the natural language to search for patterns. The following figure shows the basic concept of voice recognition.


As speech is a sound pressure wave, its conversion in to electrical signal and then in to digital signal introduces distortion. As shown in the figure, acoustic front-end requires several signal processing components such as spectral shaping, spectral analysis, spectral modeling, and parametric transformation. These components will condition the signal and establish the spectral measurements and parameters for acoustic modeling.Once robust parameterization of speech signal is established, then spectral dynamics or changes of the spectrum with respect to time will be captured. Typically, speaker recognition can be achieved by using differentiation of spectral features, which requires temporal derivatives of the voice spectrum. These temporal derivatives are commonly approximated by differentiating cepstral features using a linear regression.

\subsection{Recognition Features}
There is no "standard" set of features for speech recognition. Instead, various combinations of acoustic, articulatory, and auditory features have been utilized in a range of speech recognition systems. The most popular acoustic features have been the (LPC-derived) mel-frequency cepstrum coefficients and their derivatives [2].

\subsection{Speaker Models}
In the process of recognizing speaker voice, the speaker model will be created and trained with acoustic characteristics of the voice. The typical speaker recognition process involves two specific tasks: verification and identification. In the verification, the goal is to determine from a voice sample if a person is who he or she claims. In the identification, the goal is to determine which one of a group of known voices best matches the input voice sample. In either task the speech can be constrained to be a known phrase (text-dependent) or totally unconstrained (text-independent). The success in both tasks depends on extracting and modeling the speaker-dependent characteristics of the speech signal which can effectively distinguish one talk from another.

A brief description of some of the speaker modeling methods typically used is given below.

   \textbf{Nearest Neighbor:} In this technique, feature vectors from enrollment (training) speech 
are retained to represent the speaker. During the verification, the match score is computed as the cumulated distance of each test feature vector to its k nearest neighbors in the speaker's training vectors.

   \textbf{Neural Networks:} These models are trained to discriminate between the speaker being
modeled and some alternate speakers.

    \textbf{Hidden Markov Models (HMM):}  The temporal evolution of speech signal
features/characteristics and model statistical variations of the features are encoded to provide statistical representation of speaker.

    \textbf{Template Matching:} In this method, the model contains a template with sequence of 
feature vectors. During the verification a match score is produced by using dynamic time warping (DTW) to align and measure the similarity between test phrase and speaker template.

\subsection{Speaker Recognition Technologies} 

<<<<<TODO>>>>>>>>>>

\section{SPEECH RECOGNITION THEORY}
Speech recognition is the process of analyzing the acoustic data to extract the speech content. In this process speech will be converted in to text as first step. Then, the converted text will be fed to Natural Language Processing (NLP) algorithms for extracting the words and meaning. NLP is the processing of the text to understand the meaning of the text. Machine learning algorithms are used in conjunction with language models to recognize text in natural language processing systems, which may also employ speech models and hardware/software specialized to process and recognize speech. 

Analyzing language for its meaning is a complex task. Modern speech recognition research began in the late 1950s with the advent of the digital computer. The 1960s saw advances in the automatic segmentation of speech into units of linguistic relevance like phonemes, syllables. And now with advancements in the field of Artificial Intelligence, neural networks have been used in many aspects of speech recognition such as phoneme classification, isolated word recognition, audiovisual speech recognition, and audiovisual speaker recognition and speaker adaptation. In the context of Speech Recognition, NLP involves 4 basic steps.

  \begin{itemize}
     \item \textbf{Morphological Analysis}:
     Morphological analysis is the identification, analysis, and description of the structure of a given languageâ€™s root words,word boundaries, affixes, parts of speech, etc. The term Morpheme means the "minimal unit of meaning". For ex: if you take word "unhappiness" it has three morphemes each carrying its own meaning.
     \item \textbf{Syntactic Analysis}:
     Syntactic analysis is the process of analyzing a string of symbols in natural language conforming to the rules of a formal grammar.
     \item \textbf{Semantic Analysis}:
     Semantic analysis is the process of relating syntactic structures, from the levels of phrases, clauses, sentences and paragraphs to the level of the writing as a whole, to their language-independent meanings.
     \item \textbf{Pragmatic Analysis}:
     Pragmatic Analysis is how sentences are used in different situations and how use affects the interpretation of the sentence. Means what was said is reinterpreted as what it actually means.
  \end{itemize}

NLP techniques are broadly categorized into 

  \begin{itemize}
   \item \textbf{Rule based (knowledge driven)}:
   Rule based approach requires huge human effort to prepare the rules, parts of speech triggers etc. The  best  known  parser  with  a  rule  base  backbone  is  the  RASP  (Robust Accurate Statistical Parsing) system that combines rule-based grammar with a probabilistic parse selection model [12, 13].
   \item \textbf{Statistical based (data driven)}:
   Statistical/Data driven approaches treats natural language processing as a \textit{machine learning} problem. They use supervised or unsupervised statistical machine learning algorithms. This method applies learning algorithm to a large body of previously translated text(large data) known as a parallel corpus. 
   
   The main advantage of the statistical approach is its language Independence.Provided there are annotated data, the same algorithm can be used for learning rules or models for any language. The statistical approach is significantly  leading in terms of accuracy against manually annotated corpora, as well as in overall number of statistical parsers compared to the number of rule-based parsers. Fast, cheap computing hardware, advances in processor speed, random access memory size, secondary storage, and grid computing making Statistical approach as popular choice. One example parser with his approach is MaltParser [128], a data-driven parser-generator for dependency parsing  that  supports  several  parsing  algorithms  and  learning  algorithms and allows user-defined feature models, consisting of arbitrary combinations of lexical features, part-of-speech features and dependency features.
  \end{itemize} 

\subsection{Speech Recognition Technologies}     

<<<<<TODO>>>>>>>>>>


\section{BIG DATA CONTEXT IN SPEECH ANALYTICS}
To get better insight in to customer behavior, satisfaction, and trends information businesses are depending on big data technologies for voice analysis by analyzing large volumes of call data. The use of voice analytics combined with big data technologies will help call centers to improve performance by reducing the call time and repeat calls, providing customer satisfaction information etc.When applications need continuous recording and processing of large volumes of human speech data for home, industry or public enterprise security/information/entertainment purposes then big data technologies will help meeting the computing and storage demands.  

\section{INTEGRATED SPEECH AND VOICE RECOGNITION APPLICATIONS}
Voice biometrics, customer service, truth detection, and personal voice assistant are some of the applications currently being used by the industry with speech recognition and analytics as key underlying technologies. Voice recognition technology has been in use by security systems with voice activated locks, law enforcement and criminology for truth detection. 

In the customer service industry, speech analytics is playing key role to get complete insight in to customer behaviors and interests. Customers will interact with service providers using multiple channels such as email, social media, SMS, phone call, and in-person etc. The technology advancements are creating even more channels or options to interact with customers and service providers.  However, with speech analytics systems the business can get more hidden insights for improving the customer satisfaction and loyalty. The capabilities such as phonetic-indexing, speech-to-text transcripts, speaker separation, emotion detection, and hot topics etc. are already in use by several businesses to improve their customer service performance.

The integrated speech and voice recognition will take the solution use cases one step beyond the current applications use and help improving the business performances. For example, systems will recognize returning customers with voice recognition technology and engage them with personalized interests/conversations. 

\section{Conclusion}
The voice and speech recognition technology and NLP combined with big data technologies can be used in solving much complex problems than the current applications. Potential applications include personalized customer services, personal voice assists, and public information desks etc. Some of the unsolved technologies such as cross language translators and accurate speaker recognition are still in research, which when solved can unleash the great potential across the world.

\begin{acks}

  The authors would like to thank Dr. Gregor von Laszewski for his support and suggestions to write this paper.

\end{acks}

\bibliographystyle{ACM-Reference-Format}
\bibliography{report} 

\appendix



\end{document}
